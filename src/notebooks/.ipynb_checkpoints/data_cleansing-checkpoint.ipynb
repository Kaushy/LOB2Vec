{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/rds/general/user/kk2219/ephemeral/data/production/2016\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Setting Paths\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "project_path = os.path.abspath(os.path.join('../..'))\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "if project_path not in sys.path:\n",
    "    sys.path.append(project_path)\n",
    "\n",
    "import config\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import paths\n",
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from pylab import *\n",
    "from sklearn.preprocessing import MinMaxScaler, QuantileTransformer\n",
    "from skimage.util.shape import view_as_windows\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "# Parameters\n",
    "num_frames = 500\n",
    "\n",
    "def retrieve_cleansed_data(lob, width, filename):\n",
    "    min_max_scaler = MinMaxScaler(feature_range=(0,50))\n",
    "    quantile_transformer = QuantileTransformer()\n",
    "    \n",
    "    # As evidenced by above, we can technically select all in the second axis as there is only 1 element. However, \n",
    "    # because we need a 2d input we make it 0. The 3rd axis is side so we need this\n",
    "    lob_qty_buy = pd.DataFrame(lob['quantity'][:,0,0,0:20])\n",
    "    lob_qty_buy = lob_qty_buy.replace(0, np.NaN)\n",
    "    \n",
    "    lob_qty_sell = pd.DataFrame(lob['quantity'][:,0,1,0:20])\n",
    "    lob_qty_sell = lob_qty_sell.replace(0, np.NaN)\n",
    "  \n",
    "    lob_n, d, w, h = lob['quantity'].shape\n",
    "    b_qty = lob['quantity'][:,0,0,:]\n",
    "    s_qty = lob['quantity'][:,0,1,:]\n",
    "    lob_qty = np.stack((b_qty, s_qty), axis=2)\n",
    "\n",
    "    lob_qty = lob_qty.reshape(-1,1)\n",
    "    lob_qty = min_max_scaler.fit_transform(lob_qty)\n",
    "    lob_qty = lob_qty.reshape(lob_n, h, w)\n",
    "    \n",
    "    b_price = lob['price'][:,0,0,:]\n",
    "    s_price = lob['price'][:,0,1,:]\n",
    "    lob_price = np.stack((b_price, s_price), axis=2)\n",
    "\n",
    "    lob_price = lob_price.reshape(-1,1)\n",
    "    lob_price = min_max_scaler.fit_transform(lob_price)\n",
    "    lob_price = lob_price.reshape(lob_n, h, w)\n",
    "\n",
    "    lob_states = np.dstack((lob_qty, lob_price))\n",
    "    lob_states = lob_states.reshape(lob_n, h, w, 2)\n",
    "\n",
    "    # We use the num_frames for step count so that the windows are non-overlapping. We can also use view_as_blocks but the issue with this is that it \n",
    "    # requires precise block splits. i.e: If block does not have enough data it will not make block\n",
    "    print(lob_states.shape)\n",
    "    if ((len(lob_states) - num_frames) < 0):\n",
    "        return [], []\n",
    "    else:\n",
    "        lob_states = view_as_windows(lob_states,(width,1,1,1), step=(num_frames,1,1,1))[...,0,0,0].transpose(0,4,1,2,3)\n",
    "        labels = np.full(len(lob_states), filename)\n",
    "        return lob_states, labels\n",
    "\n",
    "\n",
    "def convert_data_to_labels(data_source, frames):\n",
    "    X = None\n",
    "    Y = None\n",
    "    for subdir, dirs, files in os.walk(data_source):\n",
    "        for file in files:\n",
    "            data_path = os.path.join(subdir, file)\n",
    "            print(data_path)\n",
    "            npy = np.load(data_path)\n",
    "            x, y = retrieve_cleansed_data(npy, frames, file)\n",
    "            if len(x) > 0:\n",
    "                if X is not None:\n",
    "                    X = np.append(X, x, axis=0)\n",
    "                else:\n",
    "                    X = x\n",
    "                    \n",
    "            if len(y) > 0:    \n",
    "                if Y is not None:\n",
    "                    Y = np.append(Y, y, axis=0)\n",
    "                else:\n",
    "                    Y = y\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "def save_data(data_source, data_dest, datatype):\n",
    "    X, Y = convert_data_to_labels(data_source, num_frames)\n",
    "\n",
    "    np.save(data_dest + '/' + str(num_frames) + datatype + 'X.npy', X)\n",
    "    np.save(data_dest + '/' + str(num_frames) + datatype + 'Y.npy', Y)\n",
    "\n",
    "    print('Written To ' + str(data_dest + '/' + str(num_frames)))\n",
    "\n",
    "# To run this you need high memory machine and will run on the compiled data from above\n",
    "def save_individual_files(data_source, save_location):\n",
    "    #X = np.load(data_source + '/500_X.npy')\n",
    "    print(data_source)\n",
    "    y = np.load(data_source + '/500_Y.npy')\n",
    "   # {np.save(save_location + 'X/' + str(k) + '.npy', v) for k, v in enumerate(X)}\n",
    "    Y_numeric = [config.label_dict[v] for v in y]\n",
    "    np.save(save_location + 'Y.npy', Y_numeric)\n",
    "   # {np.save(save_location + 'Y/' + str(k) + '.npy', v) for k, v in enumerate(y)}\n",
    "\n",
    "# Test\n",
    "\n",
    "# 2016\n",
    "#save_data(paths.source_2016, paths.dest_2016, '_')\n",
    "\n",
    "# 2017\n",
    "#save_data(paths.source_2017, paths.dest_2017, '_')\n",
    "\n",
    "# Test Data\n",
    "#save_data(paths.source_val_2017, paths.dest_2017, '_Test2017_')\n",
    "\n",
    "save_individual_files(paths.dev_dest, paths.dev_dest_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/rds/general/user/kk2219/ephemeral/data/production_generator/2016/\n"
     ]
    }
   ],
   "source": [
    "print(paths.dest_2016_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.load(paths.dest_2016_generator + 'Y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148189\n"
     ]
    }
   ],
   "source": [
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "print(y[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:spoofing_new]",
   "language": "python",
   "name": "conda-env-spoofing_new-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
