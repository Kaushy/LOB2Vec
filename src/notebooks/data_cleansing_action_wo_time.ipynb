{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Setting Paths\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "project_path = os.path.abspath(os.path.join('../..'))\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "if project_path not in sys.path:\n",
    "    sys.path.append(project_path)\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import paths\n",
    "import model\n",
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import logging\n",
    "from pylab import *\n",
    "from os.path import basename\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import MinMaxScaler, QuantileTransformer\n",
    "from skimage.util.shape import view_as_windows\n",
    "from scipy.ndimage.interpolation import shift\n",
    "\n",
    "\n",
    "# Parameters\n",
    "num_frames = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_cleansed_data(lob, y_df, z_df, width, filename):\n",
    "    min_max_scaler = MinMaxScaler(feature_range=(0,50))\n",
    "    quantile_transformer = QuantileTransformer()\n",
    "    \n",
    "    # As evidenced by above, we can technically select all in the second axis as there is only 1 element. However, \n",
    "    # because we need a 2d input we make it 0. The 3rd axis is side so we need this\n",
    "    lob_qty_buy = pd.DataFrame(lob['quantity'][:,0,0,0:20])\n",
    "    lob_qty_buy = lob_qty_buy.replace(0, np.NaN)\n",
    "    \n",
    "    lob_qty_sell = pd.DataFrame(lob['quantity'][:,0,1,0:20])\n",
    "    lob_qty_sell = lob_qty_sell.replace(0, np.NaN)\n",
    "  \n",
    "    lob_n, d, w, h = lob['quantity'].shape\n",
    "    print(h)\n",
    "    b_qty = lob['quantity'][:,0,0,:]\n",
    "    s_qty = lob['quantity'][:,0,1,:]\n",
    "    lob_qty = np.stack((b_qty, s_qty), axis=2)\n",
    "\n",
    "    lob_qty = lob_qty.reshape(-1,1)\n",
    "    lob_qty = min_max_scaler.fit_transform(lob_qty)\n",
    "    lob_qty = lob_qty.reshape(lob_n, h, w)\n",
    "    \n",
    "    b_price = lob['price'][:,0,0,:]\n",
    "    s_price = lob['price'][:,0,1,:]\n",
    "    lob_price = np.stack((b_price, s_price), axis=2)\n",
    "\n",
    "    lob_price = lob_price.reshape(-1,1)\n",
    "    lob_price = min_max_scaler.fit_transform(lob_price)\n",
    "    lob_price = lob_price.reshape(lob_n, h, w)\n",
    "    \n",
    "    lob_states = np.dstack((lob_qty, lob_price))\n",
    "    lob_states = lob_states.reshape(lob_n, h, w, 2)\n",
    "\n",
    "    # We use the num_frames for step count so that the windows are non-overlapping. We can also use view_as_blocks but the issue with this is that it \n",
    "    # requires precise block splits. i.e: If block does not have enough data it will not make block\n",
    " \n",
    "    if ((len(lob_states) - num_frames) < 0):\n",
    "        return [], []\n",
    "    else:\n",
    "        # We are shifting Y values by one, since what we want from a state is the prediction of the action from that state. Without this shift, Y value\n",
    "        # gives the action that achieved this current state. With this shift the last state will have action = 0, which is did nothing\n",
    "        z_df_shifted = shift(z_df, -1, cval=0)\n",
    "        y_df_shifted = shift(y_df, shift=[-1,0], cval=0)    \n",
    "        \n",
    "        # Use this to get non-overlapping windows. Y value calculation for this not complete\n",
    "        lob_states = view_as_windows(lob_states,(width,1,1,1), step=(width,1,1,1))[...,0,0,0].transpose(0,4,1,2,3)\n",
    "        y_df_shifted = y_df_shifted[num_frames-1::num_frames]\n",
    "        z_df_shifted = z_df_shifted[num_frames-1::num_frames]\n",
    "        \n",
    "        # Use this for overlapping windows. Y value calculation also complete\n",
    "        #lob_states = view_as_windows(lob_states,(width,1,1,1))[...,0,0,0].transpose(0,4,1,2,3)\n",
    "        #y_df_shifted = y_df_shifted[num_frames-1:len(y_df_shifted)]\n",
    "        logging.error(lob_states.shape)\n",
    "        logging.error(len(y_df_shifted))\n",
    "        return lob_states, y_df_shifted, z_df_shifted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data_to_labels(data_source, frames):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    X = None\n",
    "    Y = None\n",
    "    Z = None\n",
    "        \n",
    "    for subdir, dirs, files in os.walk(data_source):\n",
    "        for file in files:\n",
    "            data_path = os.path.join(subdir, file)\n",
    "            my_path = Path(data_path)\n",
    "            date_path = my_path.parent.parent\n",
    "            x_path = date_path / 'X' / file\n",
    "            z_path = date_path / 'Z' / file\n",
    "            XorY = basename(my_path.parent)\n",
    "            if XorY == 'Y':\n",
    "                npy_y = np.load(data_path, allow_pickle=True)\n",
    "                npy_x = np.load(x_path, allow_pickle=True)\n",
    "                npy_z = np.load(z_path, allow_pickle=True)\n",
    "       \n",
    "                print(data_path)\n",
    "                print(x_path)\n",
    "                print(z_path)\n",
    "                x, y, z = retrieve_cleansed_data(npy_x, npy_y, npy_z, frames, file)\n",
    "                if len(x) > 0:\n",
    "                    if X is not None:\n",
    "                        X = np.append(X, x, axis=0)\n",
    "                    else:\n",
    "                        X = x\n",
    "\n",
    "                if len(y) > 0:    \n",
    "                    if Y is not None:\n",
    "                        Y = np.append(Y, y, axis=0)\n",
    "                    else:\n",
    "                        Y = y\n",
    "                \n",
    "                if len(z) > 0:    \n",
    "                    if Z is not None:\n",
    "                        Z = np.append(Z, z, axis=0)\n",
    "                    else:\n",
    "                        Z = z\n",
    "    return X, Y, Z\n",
    "        \n",
    "\n",
    "def save_data(data_source, data_dest, datatype):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    X, Y = convert_data_to_labels(data_source, num_frames)\n",
    "    np.save(data_dest + str(num_frames) + datatype + 'X.npy', X)\n",
    "    np.save(data_dest + str(num_frames) + datatype + 'Y.npy', Y)\n",
    "    print('Written To ' + str(data_dest + str(num_frames)))\n",
    "\n",
    "    \n",
    "# To run this you need high memory machine\n",
    "def save_individual_files(data_source, save_location, frames):\n",
    "    if not os.path.exists(str(save_location) + str(frames) + '_X/'):\n",
    "        os.makedirs(str(save_location) + str(frames) + '_X/')\n",
    "    X, Y, Z = convert_data_to_labels(data_source, frames)\n",
    "    {np.save(save_location + str(frames) + '_X/' + str(k) + '.npy', v) for k, v in enumerate(X)}\n",
    "    np.save(save_location + str(frames) + '_Y.npy', Y)\n",
    "    np.save(save_location + str(frames) + '_Z.npy', Z)\n",
    "    logging.error('Written To ' + str(save_location) + str(frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/rds/general/user/kk2219/ephemeral/data/lob_2_vec/full_depth/train_2016/20190410/Y/SJM_NASDAQ.npy\n",
      "/rds/general/user/kk2219/ephemeral/data/lob_2_vec/full_depth/train_2016/20190410/X/SJM_NASDAQ.npy\n",
      "/rds/general/user/kk2219/ephemeral/data/lob_2_vec/full_depth/train_2016/20190410/Z/SJM_NASDAQ.npy\n",
      "30\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'min_max_scaler' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-587fac5169b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#save_individual_files(paths.source_test_dev, paths.generator_test_dev, num_frames)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0msave_individual_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource_train_2016\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator_train_dev\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'normalised/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0msave_individual_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource_val_2016\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator_val_dev\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'normalised/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0msave_individual_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource_test_2016\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator_test_dev\u001b[0m  \u001b[0;34m+\u001b[0m  \u001b[0;34m'normalised/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-0665e44470a5>\u001b[0m in \u001b[0;36msave_individual_files\u001b[0;34m(data_source, save_location, frames)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_location\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_X/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_location\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_X/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_data_to_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_source\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0;34m{\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_location\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_X/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_location\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_Y.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-0665e44470a5>\u001b[0m in \u001b[0;36mconvert_data_to_labels\u001b[0;34m(data_source, frames)\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretrieve_cleansed_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpy_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnpy_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnpy_z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-800ae799e280>\u001b[0m in \u001b[0;36mretrieve_cleansed_data\u001b[0;34m(lob, y_df, z_df, width, filename)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mlob_qty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlob_qty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mlob_qty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin_max_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlob_qty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mlob_qty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlob_qty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlob_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'min_max_scaler' is not defined"
     ]
    }
   ],
   "source": [
    "# Dev\n",
    "#save_individual_files(paths.source_train_dev, paths.generator_train_dev, num_frames)\n",
    "#save_individual_files(paths.source_val_dev, paths.generator_val_dev, num_frames)\n",
    "#save_individual_files(paths.source_test_dev, paths.generator_test_dev, num_frames)\n",
    "\n",
    "# Real\n",
    "save_individual_files(paths.source_train, paths.generator_train_dev + 'normalised/', num_frames)\n",
    "save_individual_files(paths.source_val, paths.generator_val_dev + 'normalised/', num_frames)\n",
    "save_individual_files(paths.source_test, paths.generator_test_dev  +  'normalised/', num_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "npy_y = np.load('/rds/general/user/kk2219/ephemeral/data/lob_2_vec/full_depth/train_2016/20190410/Y/USM_NASDAQ.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  5, 11, 23],\n",
       "       [ 2, 10, 19, 34],\n",
       "       [ 1,  5, 12, 33],\n",
       "       ...,\n",
       "       [ 2,  8,  0, 50],\n",
       "       [ 2,  8,  0, 50],\n",
       "       [ 1,  3,  0, 50]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npy_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_df_shifted = shift(npy_y, shift=[-1,0], cval=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2, 10, 19, 34],\n",
       "       [ 1,  5, 12, 33],\n",
       "       [ 2, 10, 19, 34],\n",
       "       ...,\n",
       "       [ 2,  8,  0, 50],\n",
       "       [ 1,  3,  0, 50],\n",
       "       [ 0,  0,  0,  0]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_df_shifted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "npy_z = np.load('/rds/general/user/kk2219/ephemeral/data/lob_2_vec/full_depth/train_2016/20190410/Z/USM_NASDAQ.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5, 15,  6, ..., 13, 13,  3])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npy_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = np.load(paths.generator_train_2016 + '10_Y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5, 12, 33,  0],\n",
       "       [ 3,  0, 50,  0],\n",
       "       [ 5, 13, 25,  0],\n",
       "       ...,\n",
       "       [ 8,  0, 50,  0],\n",
       "       [ 8,  0, 50,  0],\n",
       "       [ 8,  0, 50,  0]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spoofing_new",
   "language": "python",
   "name": "spoofing_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}